# -*- coding: utf-8 -*-
"""crab_news&photo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T-VFIKr59hNV53rfujHuU4TQm44fga3N
"""

import requests
from bs4 import BeautifulSoup
url = requests.get("https://udn.com/news/cate/2/7227") #取得該網址的html
soup = BeautifulSoup(url.text,"html.parser") 
result = soup.select("div.story-list__text a") #取得class為story-list__text的 a
for titles in result:
  if titles["href"] != "#": #避開href值為空的
    print("https://udn.com/"+titles["href"]+" "+titles.text) #印出新聞網紙加上標題

img2 = pic.content#這個動作是下載
pic_out = open('img1.png','wb')#開一個圖片檔，等等要把圖片放進這邊
pic_out.write(img2)#將讀到的圖片寫入pic_out
pic_out.close()

import requests
import urllib.request
from bs4 import BeautifulSoup
import os
import time
import random
key =input() #輸入關鍵字
url = "https://www.google.com/search?q="+key+"&rlz=1C1GCEU_zh-twTW912TW913&sxsrf=ALeKk017A-fl9jExZxex4APJ5UUuxYbmVg:1597302845980&source=lnms&tbm=isch&sa=X&ved=2ahUKEwis1-jl0JfrAhXGG6YKHQ4TADQQ_AUoAXoECBoQAw&biw=1366&bih=657"
headers = {'User-Agent': 'Mozilla/5.0'} #加上header才不會被抓
p = requests.get(url, headers = headers) #p連線到url
soup = BeautifulSoup(p.content, 'html.parser') 
location = soup.find_all('img') #把location設成有<img>開頭的
folder_path='./'+key+'/' #把圖片儲存在跟keyword相同的資料夾
os.makedirs(folder_path) #Create folder
i=0 #為了區別圖片名用的
for src in location:
  a=src.get("src") #src.get("src")會是該圖片的網址
  if a[0]=='h': #不知道為何會先讀到google的icon，所以設定成格式要是http開頭的才下載
    pic = requests.get(src.get("src")) #連線到該圖片的網址
    pic2 = pic.content #下載
    img_name = folder_path + str(i + 1) + '.png' #建立圖片名
    pic_out = open(img_name,'wb') #開圖片檔，把圖片放過來
    pic_out.write(pic2) #寫入圖片
    pic_out.close()
    i=i+1
    time.sleep(random.uniform(0.5,0.9))
print('done')

#for i in range(10):
#  pic = location["src"]
#  pic2 = pic.content
#  pic_out = open('img'+i+'.png',folder_path)
#  pic_out.write(pic2)
#  pic_out.close()

"""# 新增區段"""

from google.colab import drive
drive.mount('/content/drive')